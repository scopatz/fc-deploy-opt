\section{Selecting Deployment Schedule Estimates}
\label{selecting}

There are three methods for choosing a new deployment schedule $\Theta$ 
to attempt to run in a simulator. The first is stochastic with weighted
probablities for the $\theta_p$.  The second does a determintsic sweep 
iteratively over all options, minimizing the dynamic time warping distance
at each point in time for each deployment parameter.  The last combines
these two and choose the one with the minimum distance to the demand curve.

All of these rely on a Gaussian process model of the production
curve. This is because constructing and evaluating GP model $g_*$ is 
significantly faster than performing even a low-fidelity simulation. 
As a demonstrative example, say each evaluation of $d(f, g_*)$ takes a tenth
of a second (which is excessively long) and $d(f, g_s)$ for a low fidelity
simulation takes ten seconds (which is reasonable), the model evaluation 
is still one hundred times faster.  Furthermore, the cost of constucting 
the GP model can is amotorized over the number of guesses that are made.

However, the choice of which $\theta_p$ to pick is extremely important
as they drive the optimization. In a vanillia stochastic algorithm, 
each $\theta_p$ would be selected as a univariate integer on the 
range $[M_p, N_p]$.  However, this ignores the distance information $D$ 
that is known about the training set that is used to create the GP in the
first place. More intelligent guesses for $\theta_p$ focus the model 
evaluations to more promising regions of the option space.  This in turn 
helps reduce the overall number of expensive simulations needed to find 
a good-enough deployment schedule.

The three WORG $\Theta$ selection methods are described in order in the 
following subsections.

\subsection{Stochastic Estimation}
\label{stochastic}

The stochastic method works by randomly choosing $\Gamma$ deployment 
schedules and evaluating $g_*(t, \Theta_\gamma)$ for each guess $\gamma$.
The $\Theta_\gamma$ which has the minimum distance $d_\gamma$ is 
taken as the best-guess deployment schedule.  The number of guesses may 
be as large or as small as desired.  However, a reasonable number to use
that spans the option space is the $L_1$ norm of the difference of the 
bounds inclusive. Namely, 
\begin{equation}
\label{Gamma-default}
\Gamma = \sum_p^P (N_p - M_p + 1)
\end{equation}
That is, each $\theta_p$ has $N_p - M_p + 1$ options, and so a reasonable
choice for $\Gamma$ is the sum of the number of independent options.

Still, each option for $\theta_p$ should not be equally likely. 
For example, if the demand curve is relatively low, the number of deployed 
facilities is unlikely to be relatively high. For this reason, the choice 
of $\theta_p$ should be weighted.  Furthermore, note that each $\theta_p$
is potentially weighted differently as they are all independent parameters.
Denote $n \in [M_p, N_p]$ such that the n-th weight for the p-th parameter 
is called $w_{n,p}$. 

To choose weights, first observe that the distances $D$ can be said to be
inversely proportional to how likely each deployment schedule in 
$\vec{\Theta}$ should be. A one-dimensional Gaussian process can thus be
constructed to model inverse distances given the values of the deployment 
parameter for each schedule, namely $\vec{\theta_p}$.  Call this model 
$d_*^{-1}$ as seen in Equation \ref{d-inv-model}.
\begin{equation}
\label{d-inv-model}
d_*^{-1}(\theta_p) = \GP\left(\mu(\vec{\theta_p}), 
                              k(\vec{\theta_p}, \vec{\theta_p}^\prime)\right)
                   \equiv \GP\left[D^{-1}\right]
\end{equation}
The construction, regression of hyperparameters, and evaluation of this 
model follows analogously to the production curve modeling presented in 
\S\ref{gp}.

The weights for $\theta_p$ are thus the normalized evaluation of the 
inverse distance model for all $m$ and $n$ defined on the p-th range.
Symbolically, 
\begin{equation}
\label{d-inv-w}
w_{n,p} = \frac{d_*^{-1}(n)}{\sum_{m=M_p}^{N_p} d_*^{-1}(m)}
\end{equation}
Equation \ref{d-inv-w} works very well as long as a valid model can 
be established.  However, this is sometimes not the case when the $\theta_p$
are degenerate, the distances are too close together, the distances are 
too close to zero, or other stability issues arise.

In cases where a valid model may not be formed for $d_*^{-1}(\theta_p)$, 
a Poisson distribution may be used instead.  Take the mean of the Poisson
distribution $\lambda$ to be the value of $\theta_p$ where the distance
is minimized.
\begin{equation}
\label{lambda}
\lambda_p = \theta_p | \mathrm{argmin}(D) 
\end{equation}
Hence, the Poisson probability distribution is, 
\begin{equation}
\label{poisson}
\mathrm{Poisson(n)} = \frac{\lambda^n}{n!} e^{-\lambda}
\end{equation}
Now, because $n$ is bounded, it is important to renormalize Equation 
\ref{poisson} when constructing stochastic weights.
\begin{equation}
\label{poisson-w}
\begin{split}
w_{n,p} & = \frac{\frac{\lambda^n}{n!} e^{-\lambda}}
                 {\sum_{m=M_p}^{N_p} \frac{\lambda^m}{m!} e^{-\lambda}}\\
        & = \frac{\lambda^n}
                 {n!\sum_{m=M_p}^{N_p} \frac{\lambda^m}{m!}}\\
\end{split}
\end{equation}
Poisson-based weights could be used exclusively, foregoing the inverse 
distance Guassian process models completely. However, the Poisson-only 
method takes into account less information about the demand-to-production
curve distances.  It was therefore observed to converge more slowly 
on an optimum than using Poisson weights as a backup.  Since the total 
number of simulations is aiming to be minimized for \emph{in situ} use, 
the WORG method uses Poisson weights as a fallback only.

After weights are computed for all $P$ deployment parameters, a set of 
$\Gamma$ deployment schedules may be stochastically chosen. The Gaussian
proccess each $g_*(\mathbf{t}, \Theta_\gamma)$ should be evaluated and the
dynamic time warping distance computed. The deployment schedule with 
the minimum distance is then selected.



\subsection{Inner Product Estimation}
\label{inner-prod}

As an alternative to the stochastic method demonstrated in \S\ref{stochastic}, 
a best-guess for $\Theta$ can also be built up iterively over all times.
The method here uses the same production curve Gaussian process $g_*$ to 
predict production levels and measure the distance to the demand curve.
However, this method tries to attempts to minimize the distance at time
$t$ and then uses this inform the minimization of $t+1$. Starting at $t=1$
and moving through the whole time grid to $t=T$, a complete deployment 
schedule is generated.

The following description is simplified for the case where $P==T$. However, 
this method is easily extended to the case where $P > T$, such as for 
multiple reactor times.  When $P > T$, group $\theta_p$ that occur on the 
same time step together and take the outter product of their options before
walking through time.

For this method, define the time sub-grid $\mathbf{t}_p$ as the sequence of
all times less than or equal to the time when parameter $p$ occurs, $t(p)$.
\begin{equation}
\label{t-p}
\mathbf{t}_p = \left\{t | t \le t(p)\right\}
\end{equation}
Now define the deployment schedule $\Theta^t$ up to time $t$ through the
following recursion relations:
\begin{equation}
\label{Theta-t}
\begin{split}
\theta_1 & = n \, | \, \mathrm{min}\left[d(f, g_*(1, n))\right]
                       \forall n\in[M_1, N_1] \\
\Theta^1 & = \left\{\theta_1\right\}\\
\theta_p & = n \, | \, \mathrm{min}\left[d(f, g_*(\mathbf{t}_p, 
                                                  \Theta^{t-1}, n))\right]
                       \forall n\in[M_p, N_p] \\
\Theta^t & = \left\{\Theta_1^{t-1}, \ldots, \Theta_{p-1}^{t-1}, \theta_p\right\}
\end{split}
\end{equation}
Equation \ref{Theta-t} has the effect of choosing the the number of 
facilities to deploy at each time step that minimizes the distance function.
The current time step uses the previous deployment schedule and only searches
the option space of the its own deployment parameters. Once $\Theta^T$ is 
reached, it is selected as the deployment schedule $\Theta$. The inner 
product method here requires the same number of evaluations of $g_*$ as 
were selected for the default value of $\Gamma$ in Equation 
\ref{Gamma-default}.



\subsection{All of the Above Estimation}
\label{all}

This method is simply to run both the stochastic method and the inner product
method and determine which has the lower $d(f, g_*)$ for the deployment 
schedules they produce.  This method contains both the advantages and 
disadvantages of the other methods.  Additionally, it has the disadvantage 
of being more computationally expensive than the methods individually.

The advantage form the stochastic method that the entire space is potentially 
searched is also confered here.  This is important since there may be other
optima far away from the current $\vec{\Theta}$ that produce lower distances.
Searching globally prevents the stochastic method from becoming stuck locally.
However, the stochastic method may take many iterations to 
make minor improvements on a $\Theta$ which is already close to a best-guess.
It is, after all, searching globally for something better.

On the other hand, the inner product method is designed to search around 
the prart of the Gaussian process model already produces good results. It
is meant to make minor adjustments as it goes.  Unfortunately, this means
the inner product method can more easily get stuck in a cycle  wehere it 
produced the same series of deployment schedules over and over again. 
It has no mechanism on its own to break out of such cycles.

With the all-of-the-above option, the job of balancing the relative merits
of the stochastic and inner product methods is left to the optimization 
loop itself.  This can be seen in \S\ref{algo}.  If the \allflag flag 
is set as th method, it is only executed as \allflag two of every four 
iterations.  Other strategies for determining how and when each of the 
three methods are used could be designed. However, any more complex strategy 
should be able to show that it meaningfully reduces the number of loop 
iterations required.

At this point, the entire WORG method has been described. From here, a 
demonstrtation of how it performs for a representative fuel cycle is 
presented. 